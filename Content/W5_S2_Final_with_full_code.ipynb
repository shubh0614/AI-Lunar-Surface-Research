{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center>  W5 S2: Implementing Convolutional Neural Network for Image Classification"
      ],
      "metadata": {
        "id": "tsM4MFakHl0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Let's first load and preprocess our images\n",
        "## Setup"
      ],
      "metadata": {
        "id": "yVl26Wc2igtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import os \n",
        "import PIL \n",
        "from PIL import Image \n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:07:10.345972Z",
          "iopub.execute_input": "2022-05-12T07:07:10.346276Z",
          "iopub.status.idle": "2022-05-12T07:07:16.110253Z",
          "shell.execute_reply.started": "2022-05-12T07:07:10.346199Z",
          "shell.execute_reply": "2022-05-12T07:07:16.109488Z"
        },
        "trusted": true,
        "id": "Mdqq5rNKigtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the flowers dataset\n",
        "## From Add data button on the top right corner, import \"flower-photos-by-the-tensorflow-team\" dataset.\n",
        "## This tutorial uses a dataset of several thousand photos of flowers. \n",
        "## The flowers dataset contains five sub-directories, one per class:\n",
        "\n",
        "flowers_photos/\n",
        "\n",
        "daisy/\n",
        "\n",
        "dandelion/\n",
        "\n",
        "roses/\n",
        "\n",
        "sunflowers/\n",
        "\n",
        "tulips/"
      ],
      "metadata": {
        "id": "mDvBEAWWigtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path for the root dataset directory\n",
        "data_dir = \"../input/flower-photos-by-the-tensorflow-team/flower_photos\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:07:21.735648Z",
          "iopub.execute_input": "2022-05-12T07:07:21.736352Z",
          "iopub.status.idle": "2022-05-12T07:07:21.74002Z",
          "shell.execute_reply.started": "2022-05-12T07:07:21.73632Z",
          "shell.execute_reply": "2022-05-12T07:07:21.739183Z"
        },
        "trusted": true,
        "id": "4VOm53AdigtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After downloading (218MB), you should now have a copy of the flower photos available. There are 3,670 total images:"
      ],
      "metadata": {
        "id": "uQF5liwuigtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how many classes we have in our dataset\n",
        "classes = os.listdir(data_dir)\n",
        "classes.remove(\"LICENSE.txt\")\n",
        "\n",
        "# counting number of images per class\n",
        "image_count = [len(os.listdir(os.path.join(data_dir,classes[i]))) for i in range(5)]\n",
        "\n",
        "print(classes)\n",
        "print(image_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:08:32.861331Z",
          "iopub.execute_input": "2022-05-12T07:08:32.86159Z",
          "iopub.status.idle": "2022-05-12T07:08:32.876381Z",
          "shell.execute_reply.started": "2022-05-12T07:08:32.861562Z",
          "shell.execute_reply": "2022-05-12T07:08:32.875651Z"
        },
        "trusted": true,
        "id": "7rta0zWjigtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before moving forward and building our super-cool TF model, let's look at the dataset a lil bit..\n",
        "\n",
        "## Let's Google our dataset!"
      ],
      "metadata": {
        "id": "g94MDOm2igtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Each directory contains images of that type of flower. Here are some roses:"
      ],
      "metadata": {
        "id": "Fhp5iuaYigtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roses = os.listdir(os.path.join(data_dir, \"roses\"))\n",
        "\n",
        "img = Image.open(os.path.join(data_dir, \"roses\", roses[8]))\n",
        "img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:15:13.211445Z",
          "iopub.execute_input": "2022-05-12T07:15:13.211731Z",
          "iopub.status.idle": "2022-05-12T07:15:13.244128Z",
          "shell.execute_reply.started": "2022-05-12T07:15:13.211679Z",
          "shell.execute_reply": "2022-05-12T07:15:13.243479Z"
        },
        "trusted": true,
        "id": "Xq-yuTSwigtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data using a Keras utility\n",
        "## Let's load these images off our Kaggle kernel using the helpful **tf.keras.utils.image_dataset_from_directory** utility.\n",
        "## Create a dataset, essentially!\n",
        "## Start with defining some parameters for the loader:"
      ],
      "metadata": {
        "id": "GU2uXbhcigta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:19:01.80215Z",
          "iopub.execute_input": "2022-05-12T07:19:01.802412Z",
          "iopub.status.idle": "2022-05-12T07:19:01.806498Z",
          "shell.execute_reply.started": "2022-05-12T07:19:01.802382Z",
          "shell.execute_reply": "2022-05-12T07:19:01.805502Z"
        },
        "trusted": true,
        "id": "Q1-irb8Yigta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It's good practice to use a validation split when developing your model. You will use 80% of the images for training and 20% for validation."
      ],
      "metadata": {
        "id": "5jDxdC2Kigta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:20:34.255888Z",
          "iopub.execute_input": "2022-05-12T07:20:34.256419Z",
          "iopub.status.idle": "2022-05-12T07:20:34.64473Z",
          "shell.execute_reply.started": "2022-05-12T07:20:34.256382Z",
          "shell.execute_reply": "2022-05-12T07:20:34.644015Z"
        },
        "trusted": true,
        "id": "jfY6v7YOigtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:19:56.679907Z",
          "iopub.execute_input": "2022-05-12T07:19:56.680624Z",
          "iopub.status.idle": "2022-05-12T07:19:57.049072Z",
          "shell.execute_reply.started": "2022-05-12T07:19:56.680584Z",
          "shell.execute_reply": "2022-05-12T07:19:57.048354Z"
        },
        "trusted": true,
        "id": "w7lkj-Ycigtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We used a random seed. What's that all about?!\n",
        "Check here: https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79"
      ],
      "metadata": {
        "id": "WU4Chprtigtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can find the class names in the class_names attribute on these datasets."
      ],
      "metadata": {
        "id": "gL8JCp2Rigtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:29:42.122249Z",
          "iopub.execute_input": "2022-05-12T07:29:42.122791Z",
          "iopub.status.idle": "2022-05-12T07:29:42.127052Z",
          "shell.execute_reply.started": "2022-05-12T07:29:42.122752Z",
          "shell.execute_reply": "2022-05-12T07:29:42.126128Z"
        },
        "trusted": true,
        "id": "Vsowj_n2igtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the data\n",
        "## Here are the first nine images from the training dataset."
      ],
      "metadata": {
        "id": "4WMwrm_Vigtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1): # Only take a single example\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:30:38.589115Z",
          "iopub.execute_input": "2022-05-12T07:30:38.589385Z",
          "iopub.status.idle": "2022-05-12T07:30:39.771175Z",
          "shell.execute_reply.started": "2022-05-12T07:30:38.589355Z",
          "shell.execute_reply": "2022-05-12T07:30:39.770525Z"
        },
        "trusted": true,
        "id": "7bTmOPkMigtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can train a model using these datasets by passing them to model.fit (shown later in this tutorial). \n",
        "### If you like, you can also manually iterate over the dataset and retrieve batches of images:"
      ],
      "metadata": {
        "id": "4gjgkbXwigtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to get batches of images and labels? \n"
      ],
      "metadata": {
        "id": "ondtVb0mkymO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:31:16.114196Z",
          "iopub.execute_input": "2022-05-12T07:31:16.114661Z",
          "iopub.status.idle": "2022-05-12T07:31:16.753116Z",
          "shell.execute_reply.started": "2022-05-12T07:31:16.114626Z",
          "shell.execute_reply": "2022-05-12T07:31:16.752357Z"
        },
        "trusted": true,
        "id": "QNhGVZgdigtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why this works: https://keras.io/api/preprocessing/image/"
      ],
      "metadata": {
        "id": "HQr4T3y6lTc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The image_batch is a tensor of the shape (32, 180, 180, 3). \n",
        "### This is a batch of 32 images of shape 180x180x3 (the last dimension refers to color channels RGB). \n",
        "### The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.\n",
        "### You can call .numpy() on either of these tensors to convert them to a numpy.ndarray."
      ],
      "metadata": {
        "id": "-L6_IeLAigtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardize the data\n",
        "### The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small.\n",
        "\n",
        "### Here, you will standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:"
      ],
      "metadata": {
        "id": "5VF3Cz1Zigtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:34:19.123641Z",
          "iopub.execute_input": "2022-05-12T07:34:19.123984Z",
          "iopub.status.idle": "2022-05-12T07:34:19.144085Z",
          "shell.execute_reply.started": "2022-05-12T07:34:19.12395Z",
          "shell.execute_reply": "2022-05-12T07:34:19.143328Z"
        },
        "trusted": true,
        "id": "2ptyYEfMigtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation\n",
        "### It takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. \n",
        "### This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "### You will implement data augmentation using the following Keras preprocessing layers: \n",
        "### **tf.keras.layers.RandomFlip**, **tf.keras.layers.RandomRotation**, and **tf.keras.layers.RandomZoom**. \n",
        "### These can be included inside your model like other layers, and run on the GPU."
      ],
      "metadata": {
        "id": "d1EAOV9Zigtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add randomflip, randomrotation and randomzoom\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\", input_shape=(img_height,img_width,3)),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:37:25.769106Z",
          "iopub.execute_input": "2022-05-12T07:37:25.769642Z",
          "iopub.status.idle": "2022-05-12T07:37:25.882222Z",
          "shell.execute_reply.started": "2022-05-12T07:37:25.769605Z",
          "shell.execute_reply": "2022-05-12T07:37:25.881579Z"
        },
        "trusted": true,
        "id": "cVQdLZmJigtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building our ML Model\n",
        "## Now, you need to do some heavy lifting here. \n",
        "## For building our ML model, we will use tensorflow and keras, these libraries makes it very easy to apply ml with very little efforts\n",
        "\n",
        "### Note: The below image is extracted from some other source and it may not exactly represent our model, \n",
        "### but it will give you a nice idea of a Convolutional Neural Network, something that we will be using here."
      ],
      "metadata": {
        "id": "263S8_bJigtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cnn-11.png](attachment:4cfeae39-c406-4949-87f2-0bc4c853022b.png)"
      ],
      "metadata": {
        "id": "BKO1WVLrigtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So, as we have seen above, for our (180 X 180 X 3) image, our first layer of neural network will contain 97,200 units in one Dense Layer. And multiplications of all the Dense layers with each other is a lot of computation for our lil computers.\n",
        "\n",
        "### That's where Convolutional layers comes into picture.\n",
        "\n",
        "### The following animation shows a convolutional layer consisting of 9 convolutional operations involving the 5x5 input matrix. Notice that each convolutional operation works on a different 3x3 slice of the input matrix. The resulting 3x3 matrix (on the right) consists of the results of the 9 convolutional operations:\n",
        "\n",
        "![](http://developers.google.com/machine-learning/glossary/images/AnimatedConvolution.gif)"
      ],
      "metadata": {
        "id": "2Vkz3wv8igte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network\n",
        "## A neural network in which at least one layer is a convolutional layer. A typical convolutional neural network consists of some combination of the following layers:\n",
        "\n",
        "### convolutional layers\n",
        "### pooling layers\n",
        "### dense layers\n",
        "\n",
        "## Convolutional neural networks have had great success in certain kinds of problems, such as image recognition."
      ],
      "metadata": {
        "id": "50pNlKFrigte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pooling\n",
        "\n",
        "![](http://developers.google.com/machine-learning/glossary/images/PoolingConvolution.svg) "
      ],
      "metadata": {
        "id": "qBhAAHZ2igte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here are some components to enhance the performance of our model\n",
        "\n",
        "## Dropout - leave out some neurons at random!\n",
        "\n",
        "## BatchNormalization - [https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739](http://)"
      ],
      "metadata": {
        "id": "KeV1oqWoigte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a model\n",
        "## For completeness, you will show how to train a simple model using the datasets you have just prepared.\n",
        "\n",
        "## The Sequential model consists of three convolution blocks (tf.keras.layers.Conv2D) with a max pooling layer (tf.keras.layers.MaxPooling2D) in each of them. \n",
        "\n",
        "## There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that is activated by a ReLU activation function ('relu')."
      ],
      "metadata": {
        "id": "AsWKFqSAigte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    data_augmentation,\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D  \n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D  \n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:55:11.989091Z",
          "iopub.execute_input": "2022-05-12T07:55:11.989382Z",
          "iopub.status.idle": "2022-05-12T07:55:12.218855Z",
          "shell.execute_reply.started": "2022-05-12T07:55:11.989351Z",
          "shell.execute_reply": "2022-05-12T07:55:12.217792Z"
        },
        "trusted": true,
        "id": "4RbyTeOmigte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose the tf.keras.optimizers.Adam optimizer and tf.keras.losses.SparseCategoricalCrossentropy loss function. \n",
        "\n",
        "## To view training and validation accuracy for each training epoch, pass the metrics argument to Model.compile."
      ],
      "metadata": {
        "id": "h6H1BKMyigte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configures the model for training.\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:55:41.555197Z",
          "iopub.execute_input": "2022-05-12T07:55:41.555464Z",
          "iopub.status.idle": "2022-05-12T07:55:41.570304Z",
          "shell.execute_reply.started": "2022-05-12T07:55:41.555434Z",
          "shell.execute_reply": "2022-05-12T07:55:41.569609Z"
        },
        "trusted": true,
        "id": "RAAIau6eigte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note: You will only train for a few epochs so this tutorial runs quickly - or use GPU feature: Accelerator!"
      ],
      "metadata": {
        "id": "PHGYX14ligtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to turn on the GPU from notebook settings\n",
        "# if you don't see the Accelarator option on the right hand side, go to your kaggle profile and verify your profile by adding your mobile number\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10\n",
        ")\n",
        "\n",
        "# it should take 30-40 seconds to train our model for first 3 epochs. And the val_accuracy should be around 0.46"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:56:02.77108Z",
          "iopub.execute_input": "2022-05-12T07:56:02.771342Z",
          "iopub.status.idle": "2022-05-12T07:57:37.111113Z",
          "shell.execute_reply.started": "2022-05-12T07:56:02.771311Z",
          "shell.execute_reply": "2022-05-12T07:57:37.110413Z"
        },
        "trusted": true,
        "id": "-gz0ojQFigtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note: You can also write a custom training loop instead of using Model.fit. \n",
        "## To learn more, visit the [Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) tutorial."
      ],
      "metadata": {
        "id": "5fNNIF26igtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize training results\n",
        "## Create plots of loss and accuracy on the training and validation sets:"
      ],
      "metadata": {
        "id": "zqwUKspRigtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-12T07:57:55.750359Z",
          "iopub.execute_input": "2022-05-12T07:57:55.75062Z",
          "iopub.status.idle": "2022-05-12T07:57:56.024146Z",
          "shell.execute_reply.started": "2022-05-12T07:57:55.750593Z",
          "shell.execute_reply": "2022-05-12T07:57:56.023457Z"
        },
        "trusted": true,
        "id": "8wlWZqAFigtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next week you will get to learn -\n",
        "\n",
        "## Transfer Learning\n",
        "## Data Annotation\n",
        "## Handling Images with OpenCV"
      ],
      "metadata": {
        "id": "oOQQyOt5igtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time for some practice questions!"
      ],
      "metadata": {
        "id": "ngZY1_eFqttp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.  Apply CNN for Image Classification.\n",
        "1. Download the notebook and import it to the Kaggle.\n",
        "\n",
        "2. From Add data button on the top right corner, import cars-image-dataset  \n",
        "  Find the dataset with this link in the Kaggle : ../input/cars-image-dataset\n",
        "\n",
        "\n",
        "Now first let's explore the dataset. Figure out the different classes present. Also see the training and testing data.\n",
        "\n",
        "a. Show the images of class **swift**.\n",
        "\n",
        "b. Load the dataset from keras utils and check if there any need for splitting dataset.\n",
        "\n",
        "c. After loading Visualize the data.\n",
        "\n",
        "d. Perform the necessary preprocessing required in the dataset(can include standardization, Normalization, data augmentation etc.) which you think are necessary to perform.  \n",
        "\n",
        "e. Train the model add layers according to you choice.\n",
        "\n",
        "f. Figure out validation accuracy for testing data and Visualize the results.\n",
        "\n"
      ],
      "metadata": {
        "id": "M3sdiIsrqyPu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-annbaTwEGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xGDk4BH3wJ4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbxsklP1wJmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thank you completing the notebook!"
      ],
      "metadata": {
        "id": "kKEqM3RiwFB3"
      }
    }
  ]
}